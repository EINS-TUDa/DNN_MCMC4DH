{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import libdnnmcmc.se_NN_lib as NN\n",
    "from libdnnmcmc.utility import import_training_data, load_scenario, LogProbDemand\n",
    "from libdnnmcmc.importance_sampling import weight_samples\n",
    "from libdnnmcmc.evaluation_functions import ed, segmented_ed, beauty_report_qdists\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "''' ++++++++++++++++++ settings ++++++++++++++++++++++++++++++++++++++'''\n",
    "testcase = 'loop'   # either 'loop' or 'tree'\n",
    "\n",
    "# MCMC settings:\n",
    "n_runs_MCMC = 2             # repeat calculations \"n_runs_MCMC\" times and average results\n",
    "n_burn_ins = [2.e4]         # number of burn-in-steps during MCMC interferrence\n",
    "num_chains = 10             # number of independent Markov-Chains, run in parallel\n",
    "num_results = int(1.e4)     # number of samples drawn per chain\n",
    "\n",
    "# evaluation settings: (calculating the energy distance is very demanding in terms of computational power and RAM)\n",
    "calculate_ED = False"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andreas Bott\\MeFlexWaerme\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "SE, VM, d_prior_dist, data_file = load_scenario(testcase)\n",
    "\n",
    "# load trained DNN model\n",
    "path = f'./models/model_{testcase}'\n",
    "model = keras.models.load_model(path, custom_objects={'MyScalingLayer': NN.MyScalingLayer,\n",
    "                                                      'MetricMAPE_T': NN.MetricMAPE_T,\n",
    "                                                      'MetricMAPE_mf': NN.MetricMAPE_mf,\n",
    "                                                      'MetricMAPE_p': NN.MetricMAPE_p,\n",
    "                                                      'LossWeightedMSE': NN.LossWeightedMSE,\n",
    "                                                      'MetricMAPE_Tend': NN.MetricMAPE_Tend})\n",
    "\n",
    "# output settings:\n",
    "file_spec = f'testcase_{testcase}'         # identifier appended to all output files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "setup evaluation metrics & load MC results as ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_nodes = SE.n_nodes\n",
    "n_edges = SE.n_edges\n",
    "n_demands = SE.n_demands\n",
    "n_states = 2*n_nodes+2*n_edges\n",
    "\n",
    "ED = np.zeros((n_runs_MCMC, 1))                     # Energy Distance\n",
    "elementwise_ED = np.zeros((n_runs_MCMC, 4))         # Energy Distance indiv. for T, mf, p, Tend\n",
    "q10dist = np.zeros((n_runs_MCMC, n_states))         # quantile error for 10% quantiles\n",
    "q5dist = np.zeros((n_runs_MCMC, n_states))          # quantile error for  5% quantiles\n",
    "mean_dist = np.zeros((n_runs_MCMC, n_states))       # mean value error\n",
    "q5dist_rel = np.zeros((n_runs_MCMC, n_states))      # relative prediction distance for  5% quantiles\n",
    "q10dist_rel = np.zeros((n_runs_MCMC, n_states))     # relative prediction distance for 10% quantiles\n",
    "\n",
    "measurement_indices = VM.measurement_indices\n",
    "measurement_stds = VM.measurement_noise\n",
    "measurement_names = [(key + ' at ' + pair[0]) for key in VM.installed_measure.keys() for pair in VM.installed_measure[key]]\n",
    "# the first 62.5k samples were used to train the DNN; exclude them for the result evaluation\n",
    "# _, MC_states = import_demand_files(data_file, 262_500)\n",
    "# MC_states = MC_states[62_500:]\n",
    "\n",
    "_, MC_states = import_training_data(data_file, 200_000, skip=62_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Perform MCMC interference for random Measurement values:\n",
    "\n",
    "The next Block performs the MCMC interference and calculates error scores for the results.\n",
    "Calculating the Energy-Score will take a lot of memory and computation power.\n",
    "Its calculation can be disabled in the settings at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "measurement values: \n",
      "mf at edge_13:   7.622763770540886\n",
      "T at DA1063:   65.01188468387012\n",
      "++++++++++++++++++++++++++++++++++++++  Perform MCMC sampling   +++++++++++++++++++++++++++++++++++++++++++\n",
      "start calculating chains\n",
      "acceptance ratio:  0.73081\n",
      "++++++++++++++++++++++++++++++++++++++++  evaluate results   ++++++++++++++++++++++++++++++++++++++++++++++\n",
      "run: 1\n",
      "measurement values: \n",
      "mf at edge_13:   7.653136073352052\n",
      "T at DA1063:   65.66200551687463\n",
      "++++++++++++++++++++++++++++++++++++++  Perform MCMC sampling   +++++++++++++++++++++++++++++++++++++++++++\n",
      "start calculating chains\n",
      "acceptance ratio:  0.76446\n",
      "++++++++++++++++++++++++++++++++++++++++  evaluate results   ++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "# numerical evaluation:\n",
    "for n_run in range(n_runs_MCMC):\n",
    "    # generate random measurement from Prior:\n",
    "    print(f'run: {n_run}')\n",
    "    measurement_values = VM.generate_random_measurements(d_prior_dist)\n",
    "    print(f'measurement values: ')\n",
    "    for i, name in enumerate(measurement_names):\n",
    "        print(f'{name}:   {measurement_values[i,0].numpy()}')\n",
    "\n",
    "    '''\n",
    "      creates a callable instance that returns the log-prob for a demand, given the prior and the measurements\n",
    "      the class wrapper is used, as the functions in the tfp.mcmc can only take one input argument which is the sample\n",
    "    '''\n",
    "    log_prob_demand_inst = LogProbDemand(d_prior_dist, model, measurement_indices, measurement_values, measurement_stds)\n",
    "\n",
    "    '''\n",
    "        define kernel;\n",
    "            method: Hamiltonian (Markov Chain) Monte Carlo,\n",
    "            log_prob of posterior: log_prob_demand_inst\n",
    "            automatic step-size adaption on the first 80% of the burnin steps\n",
    "            target acceptance rate: 75% (default)\n",
    "    '''\n",
    "    def adaptive_hmc(num_burnin_steps):\n",
    "        return tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "            tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            # tfp.experimental.mcmc.PreconditionedHamiltonianMonteCarlo(\n",
    "                target_log_prob_fn=log_prob_demand_inst,\n",
    "                num_leapfrog_steps=1,\n",
    "                step_size=0.01),\n",
    "            num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
    "\n",
    "    # this tf.function may trigger a warning for retracing. This retracing can not be avoided as the measurements may\n",
    "    # change for each iteration of the loop  -  ignore the warning\n",
    "    @tf.function\n",
    "    def run_chain_hmc(initial_state, num_results, num_burnin_steps):\n",
    "        samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "            num_results=num_results,\n",
    "            num_burnin_steps=num_burnin_steps,\n",
    "            current_state=initial_state,\n",
    "            kernel=adaptive_hmc(num_burnin_steps),\n",
    "            num_steps_between_results=1,\n",
    "            trace_fn=lambda _, pkr: pkr)\n",
    "        return samples, is_accepted\n",
    "\n",
    "    # function to sample starting points, run the chains and return the demands + states\n",
    "    def run_mcmc(num_burnin_steps, num_results):\n",
    "        initial_state = d_prior_dist.sample(num_chains)\n",
    "        initial_state = tf.Variable(initial_state)\n",
    "\n",
    "        print('start calculating chains')\n",
    "        chains, kernel_results = run_chain_hmc(initial_state, num_results, num_burnin_steps)\n",
    "        # '''\n",
    "        try:\n",
    "            print('acceptance ratio: ', np.mean(kernel_results.is_accepted))\n",
    "        except:\n",
    "            print('acceptance ratio: ', np.mean(kernel_results.inner_results.is_accepted))\n",
    "\n",
    "        dem_samples = tf.reshape(chains, shape=(-1, n_demands))\n",
    "        MCMC_states = model(dem_samples)\n",
    "\n",
    "        return dem_samples, MCMC_states, kernel_results\n",
    "\n",
    "\n",
    "    print('++++++++++++++++++++++++++++++++++++++  Perform MCMC sampling   +++++++++++++++++++++++++++++++++++++++++++')\n",
    "\n",
    "    demands_MCMC, states_MCMC, kernel_results = run_mcmc(int(n_burn_ins[0]), num_results)\n",
    "\n",
    "    #%%\n",
    "    print('++++++++++++++++++++++++++++++++++++++++  evaluate results   ++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "\n",
    "    # sampling importance resampling to gather ground truth results:\n",
    "    weights = weight_samples(MC_states, measurement_indices, measurement_stds,\n",
    "                             measurement_values, plot=False)\n",
    "    n_resample = 10000\n",
    "    weights = weights / np.sum(weights)             # normalise weights\n",
    "    sample_ind = np.random.choice(len(weights), size=n_resample, p=weights)\n",
    "    states_res  = tf.gather(MC_states, sample_ind)  # resampled states\n",
    "    weights_res = tf.gather(weights, sample_ind)    # weights associated with each resampled state\n",
    "\n",
    "    # remove constant dimensions before calculating the ED\n",
    "    y_data =  tf.sparse.sparse_dense_matmul(states_res, SE.mask_matrix_full)\n",
    "    y_model = tf.sparse.sparse_dense_matmul(states_MCMC, SE.mask_matrix_full)\n",
    "\n",
    "    if calculate_ED:\n",
    "        # ED over all dimensions\n",
    "        ED[n_run] = ed(y_data=y_data, y_model=y_model)\n",
    "        # ED for each type of state variable\n",
    "        elementwise_ED[n_run, :] = segmented_ed(y_data=y_data, y_model=y_model, segments=SE.state_dimension_segments)\n",
    "    # Quantile distances:\n",
    "    for s in range(n_states):\n",
    "        q5dist[n_run, s] = np.quantile(states_res[:, s], 0.05) - np.quantile(states_MCMC[:, s], 0.05)\n",
    "        q5dist_rel[n_run, s] = q5dist[n_run, s] / np.quantile(states_res[:, s], 0.05)\n",
    "        mean_dist[n_run, s] = (tf.reduce_mean(states_res[:, s]) - tf.reduce_mean(states_MCMC[:, s])).numpy()\n",
    "    for s in range(n_states):\n",
    "        q10dist[n_run, s] = np.quantile(states_res[:, s], 0.1) - np.quantile(states_MCMC[:, s], 0.1)\n",
    "        q10dist_rel[n_run, s] = q10dist[n_run, s] / np.quantile(states_res[:, s], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Report the results\n",
    "\n",
    "create csv files of all important results and display the quantile distances and energy distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ############################ results MCMC : ######################## \n",
      " \n",
      "\n",
      "ED:  [[0.]\n",
      " [0.]] \n",
      "\n",
      "q5-distances:\n",
      "MAE dist T 0.56 \n",
      "Max dist T 3.00 \n",
      "MAE dist mf 0.03 \n",
      "Max dist mf 0.13 \n",
      "MAE dist p 6.80\n",
      "Max dist p 94.99\n",
      "MAE dist T_end 0.44 \n",
      "Max dist T_end 2.97 \n",
      "q10-distances:\n",
      "MAE dist T 0.52 \n",
      "Max dist T 2.05 \n",
      "MAE dist mf 0.04 \n",
      "Max dist mf 0.14 \n",
      "MAE dist p 3.81\n",
      "Max dist p 42.05\n",
      "MAE dist T_end 0.42 \n",
      "Max dist T_end 2.06 \n",
      "\n",
      " \n",
      " ######################### relative results MCMC : ##################### \n",
      " \n",
      "\n",
      "q5-distances:\n",
      "MAE dist T 0.01 %\n",
      "Max dist T 0.05 %\n",
      "MAE dist mf 0.10 %\n",
      "Max dist mf 0.67 %\n",
      "MAE dist p 0.00 %\n",
      "Max dist p 0.01 %\n",
      "MAE dist T_end 0.01 %\n",
      "Max dist T_end 0.04 %\n",
      "q10-distances:\n",
      "MAE dist T 0.01 %\n",
      "Max dist T 0.03 %\n",
      "MAE dist mf 0.12 %\n",
      "Max dist mf 0.70 %\n",
      "MAE dist p 0.00 %\n",
      "Max dist p 0.01 %\n",
      "MAE dist T_end 0.01 %\n",
      "Max dist T_end 0.03 %\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(q5dist).to_csv(open(f'results/q5dist_{file_spec}.csv', 'w'), header=False, index=False)\n",
    "pd.DataFrame(q10dist).to_csv(open(f'results/q10dist_{file_spec}.csv', 'w'), header=False, index=False)\n",
    "pd.DataFrame(mean_dist).to_csv(open(f'results/meandist_{file_spec}.csv', 'w'), header=False, index=False)\n",
    "pd.DataFrame(ED).to_csv(open(f'results/ed_{file_spec}.csv', 'w'), header=False, index=False)\n",
    "pd.DataFrame(elementwise_ED).to_csv(open(f'results/ed_sep_{file_spec}.csv', 'w'), header=False, index=False)\n",
    "\n",
    "print('\\n \\n ############################ results MCMC : ######################## \\n \\n')\n",
    "print(f'ED:  {ED} \\n')\n",
    "print('q5-distances:')\n",
    "beauty_report_qdists(q5dist, SE)\n",
    "print('q10-distances:')\n",
    "beauty_report_qdists(q10dist, SE)\n",
    "\n",
    "print('\\n \\n ######################### relative results MCMC : ##################### \\n \\n')\n",
    "print('q5-distances:')\n",
    "beauty_report_qdists(q5dist_rel, SE, mode='%')\n",
    "print('q10-distances:')\n",
    "beauty_report_qdists(q10dist_rel, SE, mode='%')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}